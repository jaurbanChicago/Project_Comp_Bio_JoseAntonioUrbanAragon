---
title: "Markov Chain Model of Genetic Drift"
author: "Jose Antonio Urban Aragon, Ethan Zhong"
date: "3/16/2022"
---

# Pre-Requisites
  * [Wright-Fisher Model](https://stephens999.github.io/fiveMinuteStats/wright_fisher_model.html)
  * [Discrete Markov Chains](http://stephens999.github.io/fiveMinuteStats/markov_chains_discrete_intro.html)
  * Basic notions of probability theory
  * Basic notions of population genetics

# Introduction to Discrete Markov Chains

Before getting into the specific details of the relationship between Markov chains and genetic drift, it is necessary to briefly explain what a discrete, finite Markov chain is.    
  
Let´s consider a discrete random variable $X$, which at time points $0,1,2,3,...$, takes values $0,1,2,...,M$. Therefore, it is precise to say that each state $E_i$, $X$ takes the value $i$ [2]. This means that at each state $E_i$ at some time $t$, $X$ is in some state $E_i$. A variable is said to be **Markovian** if the probability of a certain outcome in the next time step $t+1$ depends only on the present state at time $t$ and is memoryless with regard to any previous time step $t-1,t-2,...$. Therefore, we can now define **a discrete Markov chain** as a sequence of discrete random variables in which the probability distribution of the different states at each time $t$ depends only on the state at time $t-1$ [1,2].


Some important mathematical notation to describe a discrete Markov chain is [2,3]:  
$$
P(E_{n+1}|E_{n})=i,E_{n-1}=i_{n-1},...,E_1=i_1,E_0=i_0)=P(E_{n+1}=j|E_n=i)\\
\mathbb{A \space discrete \space Markov \space is \space homogeneous \space if:}\\
P(E_{n+1}|E_{n})=P(E_i=j|E_{i-1}=i) \space \mathbb{for \space all} \space n, \mathbb{so} \space P(E_i=j|E_{i-1})=P_{ij}\\
P_{ij} \gt 0;i,j \ge 0; \sum_{j=0}^{\infty}P_{ij}=1 \\
\mathbb{A \space transition \space probability \space matrix \space can \space be \space assembled \space to \space represent \space the \space probabilities \space of \space} P_{ij} \space \\
P_{ij}= \begin{pmatrix}
p_{00} & p_{01} & ... & p_{0M}\\
p_{00} & p_{11} & ... & p_{1M} \\
.\\
.\\
.\\
p_{M0} & p_{M1} & ... & p_{MM}
\end{pmatrix} \\
\mathbb{This \space is \space an \space stochastic \space matrix, so \space all \space rows \space must \space sum \space to \space 1}
$$
The states of a discrete Markov chain are classified into the following categories [2,3,4]:  

  * **Recurrent**:State $E_i$ can reenter $E_i$ often infinitely when the chain starts at this particular $E_i$., i.e. $f_{i}=1$. 
  * **Transient**: State $E_i$ is transient if, starting at state $E_i$, the number of time periods that the process will be in $E_i$ has a geometric distribution with mean $\frac{1}{1-f_i}$.  
  * **Absorbing**: An state $E_i$ is absorbinf if the probability of ever visiting any other state is zero.  


Next, we are going to classify the chains in two different classes:  

  * **Irreducible**: All states can communicate with one another[3].
  * **Ergodic**: Irreducible, recurrent, and aperiodic. Aperiodic means all of the Markov chain states are aperiodic [3].  
  

For the remainder of this vignette, it is important to denote that we will be working with Markov chains that have no periodicities in them, which hardly arise in any genetical applications [2]. Finally, we need to define the concept of **stationary distribution** of a Markov chain. A stationary distribution may be defined with the following mathematical terms [3]:  

$$
\mathbb{Consider \space}P^t \space \mathbb{as \space t \space gets \space large}:\\
\lim_{t\to\infty}(\pi^{(0)})^TP^t=\pi^T ; \space \mathbb{the \space \pi \space vector \space is \space the \space limiting \space distribution \space of \space the \space Markov \space chain}\\
\mathbb{Stationarity \space property \space of \space \pi}:\\
\pi^T=\pi^TP; \space \mathbb{because} \space \pi_i=\sum_k \pi_kP_{ki} 
$$
For ergodic chains, the limiting distribution is also the stationary distribution and there is only one unique stationary distribution (i.e., equilibrium distribution) [3]. To obtain the stationary distribution of the Markov chain, we can use matrix exponentiation (each row of the resulting matrix will have $\pi$ in each row), solve linear equations (solve for $\pi^T=\pi^TP$), and use eigendecomposition ($\pi$ is left eigenvector of $P$, so eigendecomposition can lead to $\pi$).


# Markov Chains in Genetic Drift

A **discrete Markov chain** can be quite helpful to describe genetic drift in an ensemble of numerous identical and independent populations of a Wright-Fisher model [1]. A Markov chain model will help us understand how drift modifies, on average, the alleles frequencies of a biallelic locus in various population replicates through time. The **transition probability** for the Markov chain describing allele frequencies changes in a specific population (from an ensemble of replicate populations) is [3]:  

$$
P_{ij}=P(p_{t+1}=\frac{j}{2N}|p_t=\frac{i}{2N})={2N \choose j}(\frac{i}{2N})^j(1-\frac{i}{2N})^{2N-j} \\
\mathbb{E}[p_{t+1}=\frac{j}{2N}|p_t=\frac{i}{2N}]=p_t\\
Var(p_{t+1}=\frac{j}{2N}|p_t=\frac{i}{2N})=\frac{p_t(1-p_t)}{2N}
$$
This transition probability equation describes the probability that a given Wright-Fisher population with a exactly $i$ copies of allele $A$ in generation t has exactly $j$ copies of $A$ in generation $t+1$. This equation is another confirmation that the allele changes between discrete time units is **Markovian**, which means that the allele trajectories in $t+1$ will exclusively depend on the frequencies at $t$[1-4]. A Markov chain describing genetic drift (no mutation and no selection) can have two **absorbing states**, which are when the allele frequency $p_i=0$ (loss) or $p_i=1$ (fixation) [5]. Besides these two absobing states, allele frequency can, in principle, change from any state to other states in a single generation. However, how big or small is the change between generations, will depend, in principle, in $N$ and the frequency itself (remember the binomial sampling from the introductory [vignette](https://jaurbanchicago.github.io/docs/Genetic_Drift_Intro.html)).  

# Code Simulations of Genetic Drifts using Markov Chains  

We will use some simple code to simulate and model random genetic drift as a simple discrete Markov chain.  



```{r, message=FALSE}
# We are going to give some examples of random genetic drift trajectories using the transition probability (Pij). 
#We are going to use the CRAN R package learnPopGen created by Liam J. Revell [5]

library(learnPopGen)

# Initial frequency p=0.01,N=50,500 and 50 population replicates

genetic.drift(p0=0.01,Ne=50,nrep=50, time=100, show = "p",pause = 0.1)
genetic.drift(p0=0.01,Ne=500,nrep=50, time=100, show = "p",pause = 0.1)




# Initial frequency p=0.5,N=50,500 and 50 population replicates

genetic.drift(p0=0.5,Ne=50,nrep=50, time=100, show = "p",pause = 0.1)
genetic.drift(p0=0.5,Ne=500,nrep=50, time=100, show = "p",pause = 0.1)


# Initial frequency p=0.8,N=50,500 and 50 population replicates

genetic.drift(p0=0.8,Ne=50,nrep=50, time=100, show = "p",pause = 0.1)
genetic.drift(p0=0.8,Ne=500,nrep=50, time=100, show = "p",pause = 0.1)


```



After taking a look at these simulations, we can observe that the size of $N$ indeed affects the variability of the outcome of the random sampling in the Markov chain. We can also see that once $A$ reaches fixation or gets lost in one of the replicates, it can never get out of that particular **absorbing state**. Finally, the frequency in each state $t$ affects the variability of the trajectories and this becomes even more apparent when the allele $A$ is either close to fixation or loss in each replicate.


# Intractability of Genetic Drift as a Markov chain in a Wright-Fisher Model


One of the caveats of modeling genetic drift as a Markov chain in a Wright-Fisher population is the fact that it becomes mathematically intractable. This means that it is very difficult to obtain simple analytical results on the distributions of allele frequencies after $t$ generations of genetic drift [6]. We can iterate over and over the Markov chain transition probabilities and we would never derive analytical formulas to describe the allele frequencies distributions. [Diffusion theory](https://jaurbanchicago.github.io/docs/diffusion_process.html) has been used to approximate certain features of the distribution (**it´s still not easy and will probably require some numerical techniques!!!**) and other interesting results (fixation probabilities,equilibrium allele frequency spectrum, etc) [6]. You can find more about diffusion approximations of genetic drift in the following [vignette](https://jaurbanchicago.github.io/docs/diffusion_approx.html).


# References

1. Hamilton, M. B. (2008). *Population genetics*. John Wiley & Sons, 53-73.  
2. Ewens, W. J. (2004). Mathematical population genetics: theoretical introduction (Vol. 1). New York: Springer, 86-91.  
3. Hartl, D. L. (2020).*A primer of population genetics and genomics*. Oxford University Press,147-173.
4. Novembre,J. "Lecture: Discrete Markov Chains",February 2022, University of Chicago, Chicago, IL.
5.Revell, L. J. (2019). learnPopGen: An R package for population genetic simulation and numerical analysis. Ecology and Evolution, 9(14), 7896-7902.
6. Berg,J.J. "Lecture:Forward Models 1",February 2022, University of Chicago, Chicago, IL.






